{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gets all the edits for wikipedia pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import stringcase\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepares url and parameters for api call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = requests.Session()\n",
    "\n",
    "URL = \"https://en.wikipedia.org/w/api.php\"\n",
    "\n",
    "PARAMS = {\n",
    "    \"action\": \"query\",\n",
    "    \"format\": \"json\",\n",
    "    \"prop\": \"revisions\",\n",
    "    \"rvlimit\":\"max\",\n",
    "    \"rvprop\": \"timestamp|user|userid|sha1|flags\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates csv file for edits for each pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "loop = True\n",
    "path = \"./../DATA/Edits\"\n",
    "df = pd.read_csv(\"./../DATA/pages/pages_filtered.csv\")\n",
    "\n",
    "Path(path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    while loop:\n",
    "        PARAMS['pageids'] = row['page_id']\n",
    "        query_data = session.get(url=URL, params=PARAMS).json()\n",
    "        \n",
    "        if 'continue' in query_data and 'rvcontinue' in query_data['continue']:\n",
    "            PARAMS['rvcontinue'] = query_data['continue']['rvcontinue']\n",
    "        else: loop = False\n",
    "            \n",
    "        for revision in query_data['query']['pages']['{}'.format(row['page_id'])]['revisions']:\n",
    "                sha1 =  revision['sha1'] if 'sha1' in revision else revision['sha1hidden']\n",
    "                user = revision['user'] if 'user' in revision else revision['userhidden']\n",
    "                \n",
    "                data.append([sha1, user, revision['timestamp']])\n",
    "           \n",
    "    filtered_df = pd.DataFrame(data, columns=['sha1', 'user', 'timestamp'])\n",
    "    file_name = stringcase.snakecase( '{} {}'.format(row['title'], row['page_id'])).replace('/', '_')\n",
    "    \n",
    "    filtered_df.to_csv(\"{}/{}.csv\".format(path, file_name),encoding = \"utf-8\", index=False, header=True)\n",
    "\n",
    "    if 'rvcontinue' in PARAMS:\n",
    "        del PARAMS['rvcontinue']\n",
    "    \n",
    "    loop = True\n",
    "    data.clear()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
